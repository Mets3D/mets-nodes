Baby's first ComfyUI nodes. Some stolen, some vibe coded.

- Adjust Image: Brightness/Contrast/Saturation adjuster. Why isn't this a thing?
- CivitAI Model Downloader: I wasn't happy with the one that's online so I made my own. You can enter a model ID, your API key, a desired folder path, file name, and even model version name, and it will download it.

# ChainReplace Workflow (old)
- ChainReplace: A string node to conveniently chain search-and-replace operations together. In goes the input text, then the text to replace with, then the text to search. I use this to build "unfurling prompts", eg. by replacing <randomcolor> in my prompt with {red|green|blue|yellow|orange}.
- ExtractTagFromString: Kinda like an HTML tag, eg. if the input string is `a girl with <eye>blue eyes</eye>`, this node will extract the `blue eyes` part if you ask it to extract the `eye` tag. Useful for not having to jump between so many different input boxes for prompts, since you can eg. use <neg>to send stuff to your negative prompt</neg> or <face>to send stuff to your FaceDetailer prompt</face>.
- AutoExtractTags: Good to run at the end of your other tag processing nodes, to remove any leftovers. Additionally, if the input contains a tag with an ! like `<!eye>` then the contents of any <eye> tags will be removed. You could use this to replace `blink` in your prompt with `blink <!eye>`, so when you want to quickly make your character blink, you can just add "blink" to your prompt and it will automatically remove any descriptions of eyes. (As long as your eyes are tagged properly)
- StableRandomChoice: I wasn't happy with how ComfyUI or WildCardProcessor handles randomized elements of a prompt, such as {red|green|blue}, particularly when a lot of such randomized elements were in a prompt. When you modify the prompt without adding or removing any randomized elements, you might get a totally different result. Not with this node.

### MegaPrompt Workflow (WIP)
- MegaPrompt: This node allows controlling a sequence of 4 samplers plus a FaceDetailer at the end, but needs some manual set-up, at least until I provide a workflow file. It requries a stack of data about your checkpoints and a stack of data about your loras. You can then associate a checkpoint to one of the four "Context" outputs, by entering this syntax in the positive prompt: `<context_1:checkpoint=MyCheckpoint>tags, for, first, sampler</context_1>`. This assumes that in your checkpoint stack you have one where you set the identifier to "MyCheckpoint". It's case-insensitive. Anything between the <> tags will only be sent to the first context. The FaceDetailer will use the last context that you specified. If a Context is None, you're expected to use a Switch node from Crystools to control execution flow if you don't want to mute stuff constantly.
- Tag Stacker: Combine a bunch of tags to be used in the MegaPrompt. For example, you can specify a tag called "random clothes" with the contents "{jacket|shirt|tanktop|bikini}", and then later in the MegaPrompt you can reference this by writing `<random clothes>`. The contents will be replaced in the final prompt.
- Prepare Checkpoint: Works like the tag stacker but it lets you build a database of checkpoints, so you can easily switch checkpoints from the prompt text input box itself, as described above. The sampler/scheduler/cfg/steps/etc values will be sent to the corresponding Context
- Break Context: Lets you extract the individual pieces of data from a Context that might be relevant for rendering. You use this to hook up your KSampler, Lora Tag Loader, etc nodes.
- Break Face Context: Same as previous, but the facedetailer context has slightly different values. You still need to set up FaceDetailer using Impact Pack yourself.
